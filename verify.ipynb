{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from RzLinear import RzLinear \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checkout the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomNumbers:  tensor([2038074743,  634329019, 1825252241,  871205356,   80759397])\n",
      "RzLinear: d1xd2: 10x10 chunk_size: 4 weight_size: 100\n",
      "tensor([[19., 17., 15., 56., 54., 52., 50., 48., 46., 44.],\n",
      "        [20., 18., 16., 57., 55., 53., 51., 49., 47., 45.],\n",
      "        [21., 19., 17., 58., 56., 54., 52., 50., 48., 46.],\n",
      "        [22., 20., 18., 59., 57., 55., 53., 51., 49., 47.],\n",
      "        [75., 73., 71., 69., 67., 65., 63., 61.,  2.,  0.],\n",
      "        [76., 74., 72., 70., 68., 66., 64., 62.,  3.,  1.],\n",
      "        [77., 75., 73., 71., 69., 67., 65., 63.,  4.,  2.],\n",
      "        [78., 76., 74., 72., 70., 68., 66., 64.,  5.,  3.],\n",
      "        [88., 86., 27., 25., 23., 21., 19., 17., 15., 13.],\n",
      "        [89., 87., 28., 26., 24., 22., 20., 18., 16., 14.]], device='cuda:0',\n",
      "       grad_fn=<RzLinearFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "weight_size = 100\n",
    "input_dim = 10\n",
    "output_dim = 10\n",
    "chunk_size = 4\n",
    "\n",
    "#hashed_weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1/np.sqrt(input_dim), 1/np.sqrt(input_dim), size=((weight_size,))).astype(np.float32)))\n",
    "hashed_weight = nn.Parameter(torch.from_numpy(np.arange(weight_size).astype(np.float32)))\n",
    "rzlinear = RzLinear(input_dim, output_dim, chunk_size, hashed_weight).to(\"cuda:0\");\n",
    "\n",
    "input_v = torch.eye(input_dim).to(\"cuda:0\")\n",
    "output_v = rzlinear(input_v)\n",
    "print(output_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkout the Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomNumbers:  tensor([2038074743,  634329019, 1825252241,  871205356,   80759397])\n",
      "RzLinear: d1xd2: 1000x1000 chunk_size: 2 weight_size: 100\n",
      "torch.Size([1000, 1000])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQZElEQVR4nO3df6yeZX3H8fdnrUPAdBYpBNu61qxRgcQhDau6GbOaUH/M8sdIasJoFpImhE00Jqadf5j90QwT45RESAgoRQ2sQTIaNpykaswSBjuIGZTaUcXBkUrrb2YyBPzuj+dL8nh6Tuk5T3tOOc/7lTx57vt7X9f9XFfP4flwX8+Pk6pCkqTfW+gBSJJODQaCJAkwECRJzUCQJAEGgiSpLV3oAczV2WefXWvWrFnoYUjSK8pDDz30k6paMd2xV2wgrFmzhomJiYUehiS9oiT5n5mOuWQkSQIMBElSMxAkSYCBIElqBoIkCTAQJEntZQMhyReSHE7y6FDtrCT3JXm875cPHduR5GCSA0kuHapfnOSRPnZ9knT9tCT/1PUHkqw5sVOUJB2P47lCuBXYNKW2HdhbVeuAvb1PkvOBLcAF3eeGJEu6z43ANmBd314651XAz6vqj4B/BD4118lIkubuZQOhqr4N/GxKeTOwq7d3AZcN1e+oqueq6gngIHBJkvOAZVV1fw3+AMNtU/q8dK47gY0vXT1IkubPXD+pfG5VHQKoqkNJzun6SuA/htpNdu353p5af6nPU32uF5L8Engd8JOpD5pkG4OrDN7whjfMcei/a832f5m2/sPr3v+ybebSZ7jNbMcx2/YLNYbjHcds278S/+1O1jhm2/5UHsN8j2O27efz324u4ziRcjx/Ma3X9e+pqgt7/xdV9dqh4z+vquVJPg/cX1Vf7votwL8CTwL/UFXv6fqfAR+vqr9Isg+4tKom+9j3gUuq6qfHGtP69etrrl9dcbxP8JJ0KholHJI8VFXrpzs213cZPdPLQPT94a5PAquH2q0Cnu76qmnqv9MnyVLgDzh6iUqSdJLNNRD2AFt7eytw91B9S79zaC2DF48f7OWlZ5Ns6NcHrpzS56Vz/SXwjfIPPUvSvHvZ1xCS3A68Gzg7ySTwSeA6YHeSqxgsB10OUFX7kuwGHgNeAK6pqhf7VFczeMfS6cC9fQO4BfhSkoMMrgy2nJCZSZJm5WUDoao+NMOhjTO03wnsnKY+AVw4Tf3/6ECRJC0cP6ksSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiS2kiBkOSjSfYleTTJ7UleneSsJPclebzvlw+135HkYJIDSS4dql+c5JE+dn2SjDIuSdLszTkQkqwEPgysr6oLgSXAFmA7sLeq1gF7e58k5/fxC4BNwA1JlvTpbgS2Aev6tmmu45Ikzc2oS0ZLgdOTLAXOAJ4GNgO7+vgu4LLe3gzcUVXPVdUTwEHgkiTnAcuq6v6qKuC2oT6SpHky50Coqh8BnwaeBA4Bv6yqrwPnVtWhbnMIOKe7rASeGjrFZNdW9vbUuiRpHo2yZLScwf/1rwVeD5yZ5IpjdZmmVseoT/eY25JMJJk4cuTIbIcsSTqGUZaM3gM8UVVHqup54C7gHcAzvQxE3x/u9pPA6qH+qxgsMU329tT6UarqpqpaX1XrV6xYMcLQJUlTjRIITwIbkpzR7wraCOwH9gBbu81W4O7e3gNsSXJakrUMXjx+sJeVnk2yoc9z5VAfSdI8WTrXjlX1QJI7ge8ALwAPAzcBrwF2J7mKQWhc3u33JdkNPNbtr6mqF/t0VwO3AqcD9/ZNkjSP5hwIAFX1SeCTU8rPMbhamK79TmDnNPUJ4MJRxiJJGo2fVJYkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkAQaCJKkZCJIkwECQJDUDQZIEGAiSpGYgSJIAA0GS1AwESRJgIEiSmoEgSQIMBElSMxAkSYCBIElqBoIkCTAQJEnNQJAkASMGQpLXJrkzyfeS7E/y9iRnJbkvyeN9v3yo/Y4kB5McSHLpUP3iJI/0seuTZJRxSZJmb9QrhM8BX6uqNwNvBfYD24G9VbUO2Nv7JDkf2AJcAGwCbkiypM9zI7ANWNe3TSOOS5I0S3MOhCTLgHcBtwBU1W+q6hfAZmBXN9sFXNbbm4E7quq5qnoCOAhckuQ8YFlV3V9VBdw21EeSNE9GuUJ4I3AE+GKSh5PcnORM4NyqOgTQ9+d0+5XAU0P9J7u2sren1o+SZFuSiSQTR44cGWHokqSpRgmEpcDbgBur6iLg1/Ty0Ayme12gjlE/ulh1U1Wtr6r1K1asmO14JUnHMEogTAKTVfVA79/JICCe6WUg+v7wUPvVQ/1XAU93fdU0dUnSPJpzIFTVj4GnkrypSxuBx4A9wNaubQXu7u09wJYkpyVZy+DF4wd7WenZJBv63UVXDvWRJM2TpSP2/1vgK0l+H/gB8NcMQmZ3kquAJ4HLAapqX5LdDELjBeCaqnqxz3M1cCtwOnBv3yRJ82ikQKiq7wLrpzm0cYb2O4Gd09QngAtHGYskaTR+UlmSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCS1kQMhyZIkDye5p/fPSnJfksf7fvlQ2x1JDiY5kOTSofrFSR7pY9cnyajjkiTNzom4QrgW2D+0vx3YW1XrgL29T5LzgS3ABcAm4IYkS7rPjcA2YF3fNp2AcUmSZmGkQEiyCng/cPNQeTOwq7d3AZcN1e+oqueq6gngIHBJkvOAZVV1f1UVcNtQH0nSPBn1CuGzwMeB3w7Vzq2qQwB9f07XVwJPDbWb7NrK3p5aP0qSbUkmkkwcOXJkxKFLkobNORCSfAA4XFUPHW+XaWp1jPrRxaqbqmp9Va1fsWLFcT6sJOl4LB2h7zuBDyZ5H/BqYFmSLwPPJDmvqg71ctDhbj8JrB7qvwp4uuurpqlLkubRnK8QqmpHVa2qqjUMXiz+RlVdAewBtnazrcDdvb0H2JLktCRrGbx4/GAvKz2bZEO/u+jKoT6SpHkyyhXCTK4Ddie5CngSuBygqvYl2Q08BrwAXFNVL3afq4FbgdOBe/smSZpHJyQQqupbwLd6+6fAxhna7QR2TlOfAC48EWORJM2Nn1SWJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJbc6BkGR1km8m2Z9kX5Jru35WkvuSPN73y4f67EhyMMmBJJcO1S9O8kgfuz5JRpuWJGm2RrlCeAH4WFW9BdgAXJPkfGA7sLeq1gF7e58+tgW4ANgE3JBkSZ/rRmAbsK5vm0YYlyRpDuYcCFV1qKq+09vPAvuBlcBmYFc32wVc1tubgTuq6rmqegI4CFyS5DxgWVXdX1UF3DbUR5I0T07IawhJ1gAXAQ8A51bVIRiEBnBON1sJPDXUbbJrK3t7al2SNI9GDoQkrwG+Cnykqn51rKbT1OoY9ekea1uSiSQTR44cmf1gJUkzGikQkryKQRh8paru6vIzvQxE3x/u+iSweqj7KuDprq+apn6UqrqpqtZX1foVK1aMMnRJ0hSjvMsowC3A/qr6zNChPcDW3t4K3D1U35LktCRrGbx4/GAvKz2bZEOf88qhPpKkebJ0hL7vBP4KeCTJd7v2d8B1wO4kVwFPApcDVNW+JLuBxxi8Q+maqnqx+10N3AqcDtzbN0nSPJpzIFTVvzP9+j/Axhn67AR2TlOfAC6c61gkSaPzk8qSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJOAUCoQkm5IcSHIwyfaFHo8kjZtTIhCSLAE+D7wXOB/4UJLzF3ZUkjReTolAAC4BDlbVD6rqN8AdwOYFHpMkjZWlCz2AthJ4amh/EviTqY2SbAO29e7/Jjkwx8c7G/jJHPu+ko3jvMdxzjCe8x6bOedTv7M723n/4UwHTpVAyDS1OqpQdRNw08gPlkxU1fpRz/NKM47zHsc5w3jOexznDCd23qfKktEksHpofxXw9AKNRZLG0qkSCP8JrEuyNsnvA1uAPQs8JkkaK6fEklFVvZDkb4B/A5YAX6iqfSfxIUdednqFGsd5j+OcYTznPY5zhhM471QdtVQvSRpDp8qSkSRpgRkIkiRgDANhHL4iI8nqJN9Msj/JviTXdv2sJPclebzvly/0WE+0JEuSPJzknt4fhzm/NsmdSb7XP/O3L/Z5J/lo/24/muT2JK9ejHNO8oUkh5M8OlSbcZ5JdvRz24Ekl8728cYqEMboKzJeAD5WVW8BNgDX9Dy3A3urah2wt/cXm2uB/UP74zDnzwFfq6o3A29lMP9FO+8kK4EPA+ur6kIGb0TZwuKc863Apim1aefZ/41vAS7oPjf0c95xG6tAYEy+IqOqDlXVd3r7WQZPECsZzHVXN9sFXLYwIzw5kqwC3g/cPFRe7HNeBrwLuAWgqn5TVb9gkc+bwTskT0+yFDiDweeWFt2cq+rbwM+mlGea52bgjqp6rqqeAA4yeM47buMWCNN9RcbKBRrLvEiyBrgIeAA4t6oOwSA0gHMWbmQnxWeBjwO/Haot9jm/ETgCfLGXym5OciaLeN5V9SPg08CTwCHgl1X1dRbxnKeYaZ4jP7+NWyAc11dkLBZJXgN8FfhIVf1qocdzMiX5AHC4qh5a6LHMs6XA24Abq+oi4NcsjqWSGfWa+WZgLfB64MwkVyzsqE4JIz+/jVsgjM1XZCR5FYMw+EpV3dXlZ5Kc18fPAw4v1PhOgncCH0zyQwZLgX+e5Mss7jnD4Hd6sqoe6P07GQTEYp73e4AnqupIVT0P3AW8g8U952EzzXPk57dxC4Sx+IqMJGGwpry/qj4zdGgPsLW3twJ3z/fYTpaq2lFVq6pqDYOf6zeq6goW8ZwBqurHwFNJ3tSljcBjLO55PwlsSHJG/65vZPA62WKe87CZ5rkH2JLktCRrgXXAg7M6c1WN1Q14H/DfwPeBTyz0eE7SHP+UwaXifwHf7dv7gNcxeFfC431/1kKP9STN/93APb296OcM/DEw0T/vfwaWL/Z5A38PfA94FPgScNpinDNwO4PXSZ5ncAVw1bHmCXyin9sOAO+d7eP51RWSJGD8lowkSTMwECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqf0/qMLpD/PMC/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "weight_size = 100\n",
    "input_dim = 1000\n",
    "output_dim = 1000\n",
    "chunk_size = 2\n",
    "\n",
    "#hashed_weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1/np.sqrt(input_dim), 1/np.sqrt(input_dim), size=((weight_size,))).astype(np.float32)))\n",
    "hashed_weight = nn.Parameter(torch.from_numpy(np.arange(weight_size).astype(np.float32)))\n",
    "rzlinear = RzLinear(input_dim, output_dim, chunk_size, hashed_weight).to(\"cuda:0\");\n",
    "\n",
    "input_v = torch.eye(input_dim).to(\"cuda:0\")\n",
    "output_v = rzlinear(input_v)\n",
    "print(output_v.shape)\n",
    "\n",
    "\n",
    "plt.hist(np.array(output_v.detach().cpu()).reshape(-1), bins = int(input_dim/10))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkout the correctness of forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomNumbers:  tensor([2038074743,  634329019, 1825252241,  871205356,   80759397])\n",
      "RzLinear: d1xd2: 1000x1000 chunk_size: 5 weight_size: 100\n"
     ]
    }
   ],
   "source": [
    "weight_size = 100\n",
    "input_dim = 1000\n",
    "output_dim = 1000\n",
    "chunk_size = 5\n",
    "\n",
    "hashed_weight = nn.Parameter(torch.from_numpy(np.arange(weight_size).astype(np.float32)))\n",
    "rzlinear = RzLinear(input_dim, output_dim, chunk_size, hashed_weight).to(\"cuda:0\");\n",
    "input_v = torch.eye(input_dim).to(\"cuda:0\")\n",
    "idx_matrix = rzlinear(input_v).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 17, 15,  ..., 97, 95, 36],\n",
       "        [20, 18, 16,  ..., 98, 96, 37],\n",
       "        [21, 19, 17,  ..., 99, 97, 38],\n",
       "        ...,\n",
       "        [10,  8,  6,  ..., 88, 86, 84],\n",
       "        [11,  9,  7,  ..., 89, 87, 85],\n",
       "        [12, 10,  8,  ..., 90, 88, 86]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_matrix.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomNumbers:  tensor([2038074743,  634329019, 1825252241,  871205356,   80759397])\n",
      "RzLinear: d1xd2: 1000x1000 chunk_size: 5 weight_size: 100\n"
     ]
    }
   ],
   "source": [
    "hashed_weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1,1, size=(weight_size,)).astype(np.float32)))\n",
    "rzlinear = RzLinear(input_dim, output_dim, chunk_size, hashed_weight).to(\"cuda:0\");\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_v = torch.rand((5,input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rzlinear(input_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = hashed_weight[idx_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = torch.matmul(input_v, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OK\n"
     ]
    }
   ],
   "source": [
    "if torch.norm(out - ground_truth) == 0:\n",
    "    print(\"All OK\")\n",
    "else:\n",
    "    print(\"Issue in forward pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RzLinear import RzLinearFunction\n",
    "import torch\n",
    "from RzLinear import RzLinear \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_size = 10\n",
    "input_dim = 10\n",
    "output_dim = 10\n",
    "chunk_size = 5\n",
    "seed = 1024\n",
    "r = np.random.RandomState(seed)\n",
    "# first number is the prime, rest are random integers\n",
    "random_numbers = torch.from_numpy(np.concatenate([np.array([2038074743]), r.randint(0, 2038074743, (50,))])).to(\"cuda:0\") # set of 50 random numbers to use\n",
    "\n",
    "\n",
    "hashed_weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1,1,weight_size).astype(np.float32))).to(\"cuda:0\")\n",
    "input_v = torch.rand((5,input_dim)).to(\"cuda:0\")\n",
    "#input_v = torch.eye(2).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFunc(hashed_weight, input_v, random_numbers, input_dim, output_dim, chunk_size ):\n",
    "    out = RzLinearFunction.forwardproxy(hashed_weight, input_v, random_numbers, input_dim, output_dim, chunk_size )\n",
    "    return out, 1/input_v.shape[0] * torch.sum(out**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, val = myFunc(hashed_weight, input_v, random_numbers, input_dim, output_dim, chunk_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad= 2*out / input_v.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_grad, in_grad = RzLinearFunction.backwardproxy(grad, hashed_weight, input_v, random_numbers, input_dim, output_dim, chunk_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.6484,  -9.5888,  -8.8386, -12.2865, -15.3563, -11.7345, -16.2864,\n",
       "        -14.1761, -14.9296, -10.5635], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6687,  0.7597,  1.4698,  0.8482,  1.9203,  0.2868,  1.7425,  0.2364,\n",
       "          2.0467,  0.9236],\n",
       "        [ 1.2055,  0.7961,  1.4715,  0.6152,  2.1190,  0.2717,  1.8941,  0.0451,\n",
       "          2.2434,  0.8557],\n",
       "        [ 2.8571,  0.8230,  2.8451,  0.6676,  3.1343,  0.2012,  2.8067,  0.2628,\n",
       "          2.4895,  1.8260],\n",
       "        [ 2.4139,  0.5300,  1.8274,  1.0924,  2.5395,  0.6820,  2.4013, -0.2016,\n",
       "          1.7088,  1.3852],\n",
       "        [ 2.0194,  0.8356,  1.6253,  0.6686,  2.3886,  0.6185,  2.5521, -0.3131,\n",
       "          2.3051,  1.2970]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-4\n",
    "_, f0 = myFunc(hashed_weight, input_v, random_numbers, input_dim, output_dim, chunk_size )\n",
    "hwt_grad = torch.empty_like(hashed_weight)\n",
    "for i in range(len(hashed_weight)):\n",
    "    hwt = hashed_weight.clone()\n",
    "    hwt[i] += epsilon\n",
    "    _, fi = myFunc(hwt, input_v, random_numbers, input_dim, output_dim, chunk_size )\n",
    "    hwt_grad[i] = (fi - f0) / epsilon\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error norm tensor(0.0501, device='cuda:0')\n",
      "tensor([-12.6648,  -9.6130,  -8.8501, -12.2833, -15.3542, -11.7493, -16.2888,\n",
      "        -14.1907, -14.9536, -10.5858], device='cuda:0')\n",
      "tensor([-12.6484,  -9.5888,  -8.8386, -12.2865, -15.3563, -11.7345, -16.2864,\n",
      "        -14.1761, -14.9296, -10.5635], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print (\"error norm\", torch.norm(hwt_grad - wt_grad))\n",
    "print(hwt_grad[:10])\n",
    "print(wt_grad[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-4\n",
    "_, f0 = myFunc(hashed_weight, input_v, random_numbers, input_dim, output_dim, chunk_size )\n",
    "int_grad = torch.empty_like(input_v)\n",
    "for i in range(int_grad.shape[0]):\n",
    "    for j in range(int_grad.shape[1]):\n",
    "        inputt = input_v.clone()\n",
    "        inputt[i][j] += epsilon\n",
    "        _, fi = myFunc(hashed_weight, inputt, random_numbers, input_dim, output_dim, chunk_size)\n",
    "        int_grad[i][j] = (fi - f0) / epsilon\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error norm tensor(0.0797, device='cuda:0')\n",
      "tensor([[1.6594, 0.7439, 1.4687, 0.8392, 1.9073],\n",
      "        [1.2016, 0.8011, 1.4687, 0.6104, 2.1172],\n",
      "        [2.8419, 0.8011, 2.8229, 0.6485, 3.1281],\n",
      "        [2.4033, 0.5341, 1.8120, 1.0872, 2.5368],\n",
      "        [2.0027, 0.8392, 1.6212, 0.6485, 2.3842]], device='cuda:0')\n",
      "tensor([[1.6687, 0.7597, 1.4698, 0.8482, 1.9203],\n",
      "        [1.2055, 0.7961, 1.4715, 0.6152, 2.1190],\n",
      "        [2.8571, 0.8230, 2.8451, 0.6676, 3.1343],\n",
      "        [2.4139, 0.5300, 1.8274, 1.0924, 2.5395],\n",
      "        [2.0194, 0.8356, 1.6253, 0.6686, 2.3886]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print (\"error norm\", torch.norm(int_grad - in_grad))\n",
    "print(int_grad[:5,:5])\n",
    "print(in_grad[:5,:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
